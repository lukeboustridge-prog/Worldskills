---
phase: 01-data-import-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/scripts/survey-marking-schemes.ts
  - survey-results.json
autonomous: true

must_haves:
  truths:
    - "All 58 WSC2024 Excel files have been surveyed"
    - "Column structure variance is documented"
    - "Merged cell usage is identified"
    - "Parser configuration can be derived from survey results"
  artifacts:
    - path: "src/scripts/survey-marking-schemes.ts"
      provides: "Executable survey script using ExcelJS"
      contains: "ExcelJS"
    - path: "survey-results.json"
      provides: "Complete survey of all 58 files with column mappings"
  key_links:
    - from: "src/scripts/survey-marking-schemes.ts"
      to: "survey-results.json"
      via: "fs.writeFile"
      pattern: "survey-results.json"
---

<objective>
Survey all 58 WSC2024 marking scheme files to detect structural variance before building the parser.

Purpose: Understand column names, header positions, and merged cell patterns across all files to design a robust parser configuration. This is MANDATORY before parsing - prevents parser failures at file 45/58.
Output: survey-results.json with complete file structure analysis.
</objective>

<execution_context>
@C:\Users\LukeBoustridge\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\LukeBoustridge\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-import-foundation/01-RESEARCH.md
@.planning/phases/01-data-import-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create file survey script</name>
  <files>src/scripts/survey-marking-schemes.ts</files>
  <action>
Create the survey script at `src/scripts/survey-marking-schemes.ts`:

```typescript
import ExcelJS from 'exceljs';
import fs from 'fs/promises';
import path from 'path';

const SOURCE_DIR = 'C:\\Users\\LukeBoustridge\\Dropbox\\WSI standards and assessment\\WSC2024\\Skill Advisors\\Final MS by Skill';

interface ColumnInfo {
  name: string;
  index: number;
  sampleValues: string[];
}

interface FileStructure {
  fileName: string;
  sheetNames: string[];
  headerRow: number;
  rowCount: number;
  columnCount: number;
  hasMergedCells: boolean;
  mergedCellCount: number;
  columns: ColumnInfo[];
  encoding: string;
  errors: string[];
}

async function surveyFile(filePath: string): Promise<FileStructure> {
  const errors: string[] = [];

  try {
    const workbook = new ExcelJS.Workbook();
    await workbook.xlsx.readFile(filePath);

    // Find the main sheet (try common names first)
    let sheet = workbook.getWorksheet('Marking Scheme')
      || workbook.getWorksheet('MS')
      || workbook.worksheets[0];

    if (!sheet) {
      throw new Error('No worksheets found');
    }

    const sheetNames = workbook.worksheets.map(ws => ws.name);

    // Detect header row (first row with 3+ non-empty cells)
    let headerRow = 1;
    for (let i = 1; i <= Math.min(15, sheet.rowCount); i++) {
      const row = sheet.getRow(i);
      const values = row.values as (string | number | undefined)[];
      const nonEmpty = values.filter(v => v !== undefined && v !== null && String(v).trim() !== '').length;
      if (nonEmpty >= 3) {
        headerRow = i;
        break;
      }
    }

    // Extract column info from header row
    const headerRowData = sheet.getRow(headerRow);
    const columns: ColumnInfo[] = [];

    headerRowData.eachCell({ includeEmpty: false }, (cell, colNumber) => {
      const sampleValues: string[] = [];

      // Get sample values from next 5 data rows
      for (let r = headerRow + 1; r <= Math.min(headerRow + 6, sheet.rowCount); r++) {
        const dataCell = sheet.getRow(r).getCell(colNumber);
        const value = getCellText(dataCell, sheet);
        if (value && value.length > 0 && value.length < 100) {
          sampleValues.push(value.substring(0, 50));
        }
      }

      columns.push({
        name: getCellText(cell, sheet) || `Column${colNumber}`,
        index: colNumber,
        sampleValues: sampleValues.slice(0, 3)
      });
    });

    // Count merged cells
    const merges = (sheet as any)._merges || {};
    const mergedCellCount = Object.keys(merges).length;

    return {
      fileName: path.basename(filePath),
      sheetNames,
      headerRow,
      rowCount: sheet.rowCount,
      columnCount: sheet.columnCount,
      hasMergedCells: mergedCellCount > 0,
      mergedCellCount,
      columns,
      encoding: 'UTF-8',
      errors
    };

  } catch (error) {
    return {
      fileName: path.basename(filePath),
      sheetNames: [],
      headerRow: 0,
      rowCount: 0,
      columnCount: 0,
      hasMergedCells: false,
      mergedCellCount: 0,
      columns: [],
      encoding: 'unknown',
      errors: [error instanceof Error ? error.message : String(error)]
    };
  }
}

function getCellText(cell: ExcelJS.Cell, sheet: ExcelJS.Worksheet): string {
  // Handle merged cells - get master cell value
  if (cell.isMerged && cell.master) {
    return cell.master.text || '';
  }
  return cell.text || '';
}

async function surveyAllFiles(): Promise<void> {
  console.log(`Surveying files in: ${SOURCE_DIR}`);

  const files = await fs.readdir(SOURCE_DIR);
  const xlsxFiles = files.filter(f => f.endsWith('.xlsx') && !f.startsWith('~'));

  console.log(`Found ${xlsxFiles.length} Excel files\n`);

  const results: FileStructure[] = [];

  for (const file of xlsxFiles) {
    console.log(`  Surveying: ${file}`);
    const result = await surveyFile(path.join(SOURCE_DIR, file));
    results.push(result);

    if (result.errors.length > 0) {
      console.log(`    ERROR: ${result.errors.join(', ')}`);
    }
  }

  // Analyze variance
  const allColumnNames = new Set(
    results.flatMap(r => r.columns.map(c => c.name.toLowerCase().trim()))
  );

  const filesWithMergedCells = results.filter(r => r.hasMergedCells);
  const filesWithErrors = results.filter(r => r.errors.length > 0);

  console.log('\n=== SURVEY SUMMARY ===');
  console.log(`Total files surveyed: ${results.length}`);
  console.log(`Files with errors: ${filesWithErrors.length}`);
  console.log(`Files with merged cells: ${filesWithMergedCells.length}`);
  console.log(`Unique column names found: ${allColumnNames.size}`);
  console.log(`\nUnique column names:\n  ${Array.from(allColumnNames).sort().join('\n  ')}`);

  // Detect common column patterns for descriptor data
  const descriptorColumns = ['code', 'id', 'ref', 'aspect', 'criterion', 'criteria',
    'excellent', 'good', 'pass', 'below', 'satisfactory', 'acceptable', 'poor'];

  console.log('\n=== COLUMN PATTERN ANALYSIS ===');
  for (const pattern of descriptorColumns) {
    const matches = Array.from(allColumnNames).filter(c => c.includes(pattern));
    if (matches.length > 0) {
      console.log(`  "${pattern}": ${matches.join(', ')}`);
    }
  }

  // Save detailed results
  const outputPath = path.join(process.cwd(), 'survey-results.json');
  await fs.writeFile(outputPath, JSON.stringify({
    surveyDate: new Date().toISOString(),
    sourceDirectory: SOURCE_DIR,
    totalFiles: results.length,
    filesWithErrors: filesWithErrors.length,
    filesWithMergedCells: filesWithMergedCells.length,
    uniqueColumnNames: Array.from(allColumnNames).sort(),
    files: results
  }, null, 2));

  console.log(`\nDetailed results saved to: ${outputPath}`);
}

surveyAllFiles().catch(console.error);
```

Key features:
- Handles merged cells by checking `cell.isMerged` and accessing `cell.master`
- Detects header row automatically
- Extracts sample values for each column
- Counts merged cells per file
- Analyzes column name variance across all files
  </action>
  <verify>Run `npx tsx src/scripts/survey-marking-schemes.ts` and confirm it outputs file count</verify>
  <done>Survey script created with ExcelJS, merged cell handling, and column analysis</done>
</task>

<task type="auto">
  <name>Task 2: Execute survey and analyze results</name>
  <files>survey-results.json</files>
  <action>
1. Run the survey script:
   ```bash
   npx tsx src/scripts/survey-marking-schemes.ts
   ```

2. Review the console output for:
   - Total files surveyed (should be ~58)
   - Files with errors (investigate any)
   - Files with merged cells
   - Unique column names found

3. Open `survey-results.json` and verify:
   - All files have been processed
   - Column structures are captured
   - Header rows are detected correctly

4. Document any variance patterns discovered (different column names for same concept).

If errors occur accessing the source directory, verify the path is correct and files are accessible.
  </action>
  <verify>
- survey-results.json exists and is valid JSON
- totalFiles in JSON matches expected (~58)
- Each file entry has columns array populated
- No critical errors that would block parsing
  </verify>
  <done>Survey complete with all 58 files analyzed, column variance documented, parser configuration derivable</done>
</task>

</tasks>

<verification>
- `survey-results.json` exists in project root
- JSON contains `files` array with ~58 entries
- Each file entry has: fileName, headerRow, columns, hasMergedCells
- Column patterns for descriptor data are identified (code, criterion, excellent, good, pass, below)
- No files have critical errors preventing future parsing
</verification>

<success_criteria>
1. All 58 WSC2024 Excel files surveyed without critical errors
2. Column names cataloged and variance documented
3. Merged cell usage identified per file
4. Header row positions detected
5. Survey results JSON provides enough information to build parser configuration
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-import-foundation/01-02-SUMMARY.md`

Include in summary:
- Total files surveyed
- Column name patterns found
- Merged cell statistics
- Any files requiring special handling
</output>
